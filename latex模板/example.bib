@InProceedings{Unet2015Olaf,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@InProceedings{Isensee2019,
author="Isensee, Fabian
and Petersen, Jens
and Klein, Andre
and Zimmerer, David
and Jaeger, Paul F.
and Kohl, Simon
and Wasserthal, Jakob
and Koehler, Gregor
and Norajitra, Tobias
and Wirkert, Sebastian
and Maier-Hein, Klaus H.",
editor="Handels, Heinz
and Deserno, Thomas M.
and Maier, Andreas
and Maier-Hein, Klaus Hermann
and Palm, Christoph
and Tolxdorff, Thomas",
title="Abstract: nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation",
booktitle="Bildverarbeitung f{\"u}r die Medizin 2019",
year="2019",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="22--22",
abstract="The U-Net was presented in 2015. With its straight-forward and successful architecture it quickly evolved to a commonly used benchmark in medical image segmentation. The adaptation of the U-Net to novel problems, however, comprises several degrees of freedom regarding the exact architecture, preprocessing, training and inference.",
isbn="978-3-658-25326-4"
}

@article{Isensee2021NM,
  title={nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation},
  author={Isensee, Fabian and Jaeger, Paul F. and Kohl, Simon A.A. and Petersen, Jens and Klaus, H. Maier-Hein},
  journal={Nature Methods},
  volume={18},
  pages={203--211},
  year={2021}
}


@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{DBLP:journals/corr/abs-1207-0580,
	author    = {Geoffrey E. Hinton and
	Nitish Srivastava and
	Alex Krizhevsky and
	Ilya Sutskever and
	Ruslan Salakhutdinov},
	title     = {Improving neural networks by preventing co-adaptation of feature detectors},
	journal   = {CoRR},
	volume    = {abs/1207.0580},
	year      = {2012}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  pages={1--14},
  year={2015},
}

@article{lin2013network,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}




@article{hubel1962receptive,
  title={Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={The Journal of physiology},
  volume={160},
  number={1},
  pages={106--154},
  year={1962},
  publisher={Wiley Online Library}
}

@ARTICLE{6313076,
  author={Fukushima, Kunihiko and Miyake, Sei and Ito, Takayuki},
  journal={IEEE Transactions on Systems, Man, and Cybernetics},
  title={Neocognitron: A neural network model for a mechanism of visual pattern recognition},
  year={1983},
  volume={SMC-13},
  number={5},
  pages={826-834},
  doi={10.1109/TSMC.1983.6313076}}

@incollection{fukushima1982neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition},
  author={Fukushima, Kunihiko and Miyake, Sei},
  booktitle={Competition and cooperation in neural nets},
  pages={267--285},
  year={1982},
  publisher={Springer}
}

@inproceedings{Islam*2020How,
	title={How much Position Information Do Convolutional Neural Networks Encode?},
	author={Md Amirul Islam* and Sen Jia* and Neil D. B. Bruce},
	booktitle={International Conference on Learning Representations},
	year={2020},
	url={https://openreview.net/forum?id=rJeB36NKvB}
}

@InProceedings{Dijk_2019_ICCV,
	author = {Dijk, Tom van and Croon, Guido de},
	title = {How Do Neural Networks See Depth in Single Images?},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	month = {October},
	year = {2019}
}

@article{lecun1998gradient,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={1998},
	publisher={Ieee}
}

@article{krizhevsky2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	journal={Advances in neural information processing systems},
	volume={25},
	pages={1097--1105},
	year={2012}
}

@inproceedings{DBLP:journals/corr/SimonyanZ14a,
	author    = {Karen Simonyan and
	Andrew Zisserman},
	title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
	San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	year      = {2015},
	url       = {http://arxiv.org/abs/1409.1556},
	timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cvpr/HeZRS16,
	author    = {Kaiming He and
	Xiangyu Zhang and
	Shaoqing Ren and
	Jian Sun},
	title     = {Deep Residual Learning for Image Recognition},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
	{CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
	pages     = {770--778},
	year      = {2016},
	url       = {https://doi.org/10.1109/CVPR.2016.90},
	doi       = {10.1109/CVPR.2016.90},
	timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
	biburl    = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cvpr/SzegedyLJSRAEVR15,
	author    = {Christian Szegedy and
	Wei Liu and
	Yangqing Jia and
	Pierre Sermanet and
	Scott E. Reed and
	Dragomir Anguelov and
	Dumitru Erhan and
	Vincent Vanhoucke and
	Andrew Rabinovich},
	title     = {Going deeper with convolutions},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
	2015, Boston, MA, USA, June 7-12, 2015},
	pages     = {1--9},
	year      = {2015},
	url       = {https://doi.org/10.1109/CVPR.2015.7298594},
	doi       = {10.1109/CVPR.2015.7298594},
	timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
	biburl    = {https://dblp.org/rec/conf/cvpr/SzegedyLJSRAEVR15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Ioffe2015ICML,
	author = {Ioffe, Sergey and Szegedy, Christian},
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	year = {2015},
	publisher = {JMLR.org},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of
each layer's inputs changes during training, as the parameters of the previous layers
change. This slows down the training by requiring lower learning rates and careful
parameter initialization, and makes it notoriously hard to train models with saturating
nonlinearities. We refer to this phenomenon as internal covariate shift, and address
the problem by normalizing layer inputs. Our method draws its strength from making
normalization a part of the model architecture and performing the normalization for
each training mini-batch. Batch Normalization allows us to use much higher learning
rates and be less careful about initialization, and in some cases eliminates the need
for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization
achieves the same accuracy with 14 times fewer training steps, and beats the original
model by a significant margin. Using an ensemble of batch-normalized networks, we
improve upon the best published result on ImageNet classification: reaching 4.82%
top-5 test error, exceeding the accuracy of human raters.},
	booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
	pages = {448¨C456},
	numpages = {9},
	location = {Lille, France},
	series = {ICML'15}
}

@INPROCEEDINGS{Szegedy2016CVPR,
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Rethinking the Inception Architecture for Computer Vision}, 
  year={2016},
  volume={},
  number={},
  pages={2818-2826},
  doi={10.1109/CVPR.2016.308}}

@inproceedings{DBLP:conf/eccv/HuangSLSW16,
	author    = {Gao Huang and
	Yu Sun and
	Zhuang Liu and
	Daniel Sedra and
	Kilian Q. Weinberger},
	title     = {Deep Networks with Stochastic Depth},
	booktitle = {{ECCV} {(4)}},
	series    = {Lecture Notes in Computer Science},
	volume    = {9908},
	pages     = {646--661},
	publisher = {Springer},
	year      = {2016}
}

@article{karlik2011performance,
	title={Performance analysis of various activation functions in generalized MLP architectures of neural networks},
	author={Karlik, Bekir and Olgac, A Vehbi},
	journal={International Journal of Artificial Intelligence and Expert Systems},
	volume={1},
	number={4},
	pages={111--122},
	year={2011},
	publisher={Citeseer}
}
@inproceedings{DBLP:conf/icml/NairH10,
	author    = {Vinod Nair and
	Geoffrey E. Hinton},
	title     = {Rectified Linear Units Improve Restricted Boltzmann Machines},
	booktitle = {{ICML}},
	pages     = {807--814},
	publisher = {Omnipress},
	year      = {2010}
}
@inproceedings{maas2013rectifier,
	title={Rectifier nonlinearities improve neural network acoustic models},
	author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y and others},
	booktitle={Proc. icml},
	volume={30},
	number={1},
	pages={3},
	year={2013},
	organization={Citeseer}
}
@article{srivastava2014dropout,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The journal of machine learning research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014},
	publisher={JMLR. org}
}